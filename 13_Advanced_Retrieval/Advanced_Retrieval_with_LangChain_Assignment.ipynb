{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.1/378.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-01 15:44:50--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: ‘john_wick_1.csv’\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-03-01 15:44:50 (15.4 MB/s) - ‘john_wick_1.csv’ saved [19628/19628]\n",
            "\n",
            "--2025-03-01 15:44:50--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_2.csv’\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 15:44:50 (75.8 MB/s) - ‘john_wick_2.csv’ saved [14747/14747]\n",
            "\n",
            "--2025-03-01 15:44:50--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_3.csv’\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 15:44:50 (32.5 MB/s) - ‘john_wick_3.csv’ saved [13888/13888]\n",
            "\n",
            "--2025-03-01 15:44:51--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: ‘john_wick_4.csv’\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-03-01 15:44:51 (9.54 MB/s) - ‘john_wick_4.csv’ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 2, 26, 15, 45, 0, 179180)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick based on the reviews provided.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for \"John Wick 3\". Here is the URL to that review: \\'/review/rw4854296/?ref_=tt_urv\\''"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'John Wick is an ex-hitman who comes out of retirement to track down the gangsters that killed his dog and took everything from him. In seeking vengeance, he unleashes a maelstrom of destruction against those who wronged him and finds himself dragged into an impossible task. The legendary hitman is forced to unearth his identity and carry out a relentless vendetta. Throughout the movie, John Wick faces numerous challenges and battles against bounty-hunting killers and professional assassins seeking to claim the bounty on his head.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Opinions about John Wick seem to vary based on the reviews provided. Some people really enjoyed it, while others feel it was lacking or disappointing.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There is no review with a rating of 10 in the provided context.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, the action is beautifully choreographed, the setup is emotional for an action flick, and Keanu Reeves stars in it. It is highly recommended for those who enjoy action movies.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick based on the reviews provided.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n- Review_Title: A Masterpiece & Brilliant Sequel\\n- Review_Url: [Click here to access the review](https://www.imdb.com/review/rw4854296/?ref_=tt_urv)'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, the character John Wick, played by Keanu Reeves, gets pulled back into the world of crime and assassinations when a mobster named Santino D'Antonio forces him to complete a task that leads to a contract being put on his life. Wick then sets out to seek revenge and take down Santino.\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick. The reviews mentioned how the film was slick, violent fun, full of stylish action sequences, and a welcomed return for Keanu Reeves to the genre. Reviewers highly recommended the movie, especially to action buffs, and praised the choreography, pacing, and overall entertainment value of the film.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I\\'m sorry, there are no reviews with a rating of 10 for the movie \"John Wick 4.\"'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, a retired assassin named John Wick, played by Keanu Reeves, comes out of retirement after someone kills his dog and steals his car. This leads to a lot of carnage as John seeks revenge and gets pulled back into the world of assassins. The story involves John traveling to various locations like Italy, Canada, and Manhattan, killing numerous assassins along the way to settle old debts and seek vengeance.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_59665/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Overall, people have generally liked the John Wick series.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review: \\n\\n- https://www.imdb.com/review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, retired assassin John Wick comes out of retirement to seek vengeance when his dog is killed and his car is stolen. He ends up getting involved in a task to help take over the Assassin's Guild, traveling to Italy, Canada, and Manhattan to kill numerous assassins.\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, it seems that people generally liked John Wick. The movie received positive comments such as \"this marks the best action film of the year,\" \"slick, violent fun,\" and \"the action is beautifully choreographed.\" Overall, the reviews indicate that John Wick was well-received by viewers.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3\". Here is the URL to that review: \\'/review/rw4854296/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In \"John Wick,\" an ex-hit-man comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. Throughout the movie, he faces numerous adversaries and engages in intense action sequences to achieve his goal of retribution.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, it seems that generally, people enjoyed the John Wick movies.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is one review with a rating of 10. Here is the URL to that review:\\n- /review/rw4854296/?ref_=tt_urv\\n\\nIf you have any more questions or need further assistance, feel free to ask!'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, the main character seeks revenge on the people who took something he loved from him, which in this case was his dog. This sets off a chain of events involving action-packed sequences and intense confrontations with various antagonists.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7b44e48c62b49e79963846c4c5b17c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "316e40614e7c48539668691b6a617c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node ba7b5e7c-fd0a-4268-8a3a-ec0dec87507c does not have a summary. Skipping filtering.\n",
            "Node 02e5bad5-bb29-46bc-a4bf-4d7cc4e0f79c does not have a summary. Skipping filtering.\n",
            "Node 6bf303a8-4ad5-4ea8-a04a-5a11301c2425 does not have a summary. Skipping filtering.\n",
            "Node 870d8e98-ce0b-4fe5-8482-3529e4a8b3c7 does not have a summary. Skipping filtering.\n",
            "Node 25d7c820-b86f-46d7-b865-3cc37629d568 does not have a summary. Skipping filtering.\n",
            "Node 2ac5ed3b-1ba9-4447-a270-338e050f6df7 does not have a summary. Skipping filtering.\n",
            "Node 44a487d9-4e71-49a3-8573-2ba2178cb7d2 does not have a summary. Skipping filtering.\n",
            "Node 02180d9e-3a40-43ed-8288-866f2610cb52 does not have a summary. Skipping filtering.\n",
            "Node b2582e93-bb5b-4355-b2e9-4917041c6ea6 does not have a summary. Skipping filtering.\n",
            "Node 5fcdae62-166f-4dc4-ad02-ba9140ceedb4 does not have a summary. Skipping filtering.\n",
            "Node 46bbf4ee-4875-4506-aa84-821d1d99860d does not have a summary. Skipping filtering.\n",
            "Node 05505b54-65ab-438a-b486-cd25be92ebce does not have a summary. Skipping filtering.\n",
            "Node d40ff664-aa12-446e-b0bd-adbbdf0fe6fa does not have a summary. Skipping filtering.\n",
            "Node 2ddaab28-c99b-45e4-b711-2a10530eeb14 does not have a summary. Skipping filtering.\n",
            "Node a5660315-b76d-46ff-a2e4-dc7a86c460ca does not have a summary. Skipping filtering.\n",
            "Node 7a43e250-3f6b-437b-900d-bded66deb997 does not have a summary. Skipping filtering.\n",
            "Node 0b9eaac4-8af3-406e-b283-c895a44d935f does not have a summary. Skipping filtering.\n",
            "Node a54da646-1b97-4f43-8e2a-fae8f74cc39f does not have a summary. Skipping filtering.\n",
            "Node 818668a4-3804-4722-ad34-37d2cd8caf0c does not have a summary. Skipping filtering.\n",
            "Node cfe223a8-fa09-4c89-9f9d-32918fee7a4b does not have a summary. Skipping filtering.\n",
            "Node 5996abfa-a72a-4413-bc9a-875990f370b2 does not have a summary. Skipping filtering.\n",
            "Node 4f76b276-ffd6-43ca-b96f-4797a0c3a11b does not have a summary. Skipping filtering.\n",
            "Node 687f2095-4263-476e-b17d-c39eecc327b5 does not have a summary. Skipping filtering.\n",
            "Node 1b9c51ee-29d9-4223-be29-0de7bd68f188 does not have a summary. Skipping filtering.\n",
            "Node e91638ea-2ab3-4406-b075-b106930594b0 does not have a summary. Skipping filtering.\n",
            "Node addd9054-0e37-4c43-873c-952c8016e15f does not have a summary. Skipping filtering.\n",
            "Node 4fcc26c9-ed65-4eb9-9b68-d4b88d3c4236 does not have a summary. Skipping filtering.\n",
            "Node 7a24994e-d2b3-4759-b2cb-e6b41c306872 does not have a summary. Skipping filtering.\n",
            "Node d0c48994-a412-460b-8a06-b17192327e59 does not have a summary. Skipping filtering.\n",
            "Node f6a73c51-6331-49d5-8a60-9b569dad01c1 does not have a summary. Skipping filtering.\n",
            "Node 1f0aa478-18b8-4aac-9baa-10ddcf111097 does not have a summary. Skipping filtering.\n",
            "Node 30362f44-5d6b-4331-8cd8-9191253e14e5 does not have a summary. Skipping filtering.\n",
            "Node cb94d14b-0a22-4300-a284-98c62455c2fa does not have a summary. Skipping filtering.\n",
            "Node 672e2053-89c8-4a19-8d15-4fc4b076ef68 does not have a summary. Skipping filtering.\n",
            "Node 0700c39c-98d1-4609-a818-a58dd8029f8c does not have a summary. Skipping filtering.\n",
            "Node 39cc976e-e369-46e2-a161-fa8270a43d4e does not have a summary. Skipping filtering.\n",
            "Node a69bc023-072a-49ee-af09-849ca9cfb966 does not have a summary. Skipping filtering.\n",
            "Node 0db7a8ef-fc58-45b1-997f-753b6de942d8 does not have a summary. Skipping filtering.\n",
            "Node 98da673b-053c-40c7-b8d6-884217a71a96 does not have a summary. Skipping filtering.\n",
            "Node f0f04479-d536-4195-ae37-451d30827071 does not have a summary. Skipping filtering.\n",
            "Node 4a4e48ba-c524-4565-bea6-8e354483ebda does not have a summary. Skipping filtering.\n",
            "Node 26967acd-7d21-422c-89f0-10d569f47032 does not have a summary. Skipping filtering.\n",
            "Node e516b669-8ed7-4a7f-b338-2938c1abfa8a does not have a summary. Skipping filtering.\n",
            "Node 2ea347d4-e398-45f5-b230-ca5f2cdd5e04 does not have a summary. Skipping filtering.\n",
            "Node 2ec3d900-3779-4fad-b929-21e6a2cf75d0 does not have a summary. Skipping filtering.\n",
            "Node fea82c98-4b4e-4283-895d-103641835502 does not have a summary. Skipping filtering.\n",
            "Node c944086c-c705-4731-b897-ae68adfce35c does not have a summary. Skipping filtering.\n",
            "Node f5d35a1f-4231-4e4b-8ead-f187a128866c does not have a summary. Skipping filtering.\n",
            "Node 8ce93ea4-b64e-48fa-b791-c3e42d7bed2f does not have a summary. Skipping filtering.\n",
            "Node 04b88791-ef46-49d8-a4a4-c1e5d34d043d does not have a summary. Skipping filtering.\n",
            "Node 8c2b3d91-5cb3-47cd-be5b-19bdb8dd05e3 does not have a summary. Skipping filtering.\n",
            "Node 1d514c3e-9683-4a3d-a6fe-9c0de22fa1c7 does not have a summary. Skipping filtering.\n",
            "Node 866a5250-cf1d-44ca-bd8f-9fa264ec716e does not have a summary. Skipping filtering.\n",
            "Node 5a845d4c-0291-475b-b9f2-6194315a32f6 does not have a summary. Skipping filtering.\n",
            "Node 5929c403-ee93-49b7-9c84-4d79e30d7de0 does not have a summary. Skipping filtering.\n",
            "Node aaa40140-8784-4347-8504-41ac987ac825 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c56b6122e4414a9784730f33a017fa8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/244 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b372322e6eb4afb8950750613c1b9cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6417462765164c0596b5a17185aa859c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "036b3437ab544e9e952f3f374337ee8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7607575eb8b4744b831b7f3d4039a1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does John Wick compare to Liam Neeson's ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whos Jon Wick?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why Keanu so good in John Wick?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What role do Russian mobsters play in the movi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Whoo is Jon Wick?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What makes the action sequences in John Wick s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does Ian McShane's character influence Joh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What elements did John Wick 3 incorporate to c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does the action and style in 'John Wick: C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Wut makes Keanu's action in John Wick so amazin?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions\n",
              "0  How does John Wick compare to Liam Neeson's ro...\n",
              "1                                     Whos Jon Wick?\n",
              "2                    Why Keanu so good in John Wick?\n",
              "3  What role do Russian mobsters play in the movi...\n",
              "4                                  Whoo is Jon Wick?\n",
              "5  What makes the action sequences in John Wick s...\n",
              "6  How does Ian McShane's character influence Joh...\n",
              "7  What elements did John Wick 3 incorporate to c...\n",
              "8  How does the action and style in 'John Wick: C...\n",
              "9   Wut makes Keanu's action in John Wick so amazin?"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extract all questions from the dataset generated by Ragas\n",
        "df_questions = pd.DataFrame({\"Questions\": [row.eval_sample.user_input for row in dataset]})\n",
        "\n",
        "# Display the table\n",
        "display(df_questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define our retrievers that we need to evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "retrieval_chains = {\n",
        "    \"BM25\": bm25_retrieval_chain,\n",
        "    \"Naive\": naive_retrieval_chain,\n",
        "    \"Multi-Query\": multi_query_retrieval_chain,\n",
        "    \"Parent-Document\": parent_document_retrieval_chain,\n",
        "    \"Contextual Compression\": contextual_compression_retrieval_chain,\n",
        "    \"Ensemble\": ensemble_retrieval_chain,\n",
        "    \"Semantic\": semantic_retrieval_chain\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run our evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating BM25 retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b29b1dd4ee145a6befa1f6e40c9de40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Naive retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad1c0d5eee2a415aa9732e37c301e83a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Multi-Query retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6580151317924ab6be8f346080a4b076",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Parent-Document retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c06fc769cd94b72bdf6b15f0881b349",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Contextual Compression retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3936d70f6f184f288b9f308b7617e970",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Ensemble retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f024e004e9aa48e5a11557d4f574b519",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[5]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Semantic retriever...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fe7bfc7f9bd4474b5f992245ede14ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[44]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
            "Exception raised in Job[50]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
            "Exception raised in Job[41]: TimeoutError()\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "If using all scalar values, you must pass an index",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[58], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m     retrieval_results[name] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Convert results into a dataframe\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m df_results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieval_results\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[1;32m     62\u001b[0m display(df_results)\n",
            "File \u001b[0;32m~/Dev/AIE5/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[0;32m~/Dev/AIE5/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Dev/AIE5/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[0;32m~/Dev/AIE5/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
            "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from ragas import EvaluationDataset, evaluate, RunConfig\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import (\n",
        "    LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import AIMessage  # Import AIMessage for type checking\n",
        "\n",
        "# Define evaluator model\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "\n",
        "# Set run config\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "# Dictionary to store evaluation results\n",
        "retrieval_results = {}\n",
        "\n",
        "# Evaluate each retrieval chain\n",
        "for name, retrieval_chain in retrieval_chains.items():\n",
        "    print(f\"Evaluating {name} retriever...\")\n",
        "\n",
        "    # Generate responses using the retrieval chain\n",
        "    for test_row in dataset:\n",
        "        response = retrieval_chain.invoke({\"question\": test_row.eval_sample.user_input})\n",
        "\n",
        "        # Extract response content safely\n",
        "        test_row.eval_sample.response = (\n",
        "            response[\"response\"].content if isinstance(response[\"response\"], AIMessage) else str(response[\"response\"])\n",
        "        )\n",
        "        \n",
        "        # Extract retrieved contexts\n",
        "        test_row.eval_sample.retrieved_contexts = [\n",
        "            context.page_content for context in response[\"context\"]\n",
        "        ]\n",
        "\n",
        "    # Convert dataset to EvaluationDataset format\n",
        "    evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "    # Run evaluation\n",
        "    result = evaluate(\n",
        "        dataset=evaluation_dataset,\n",
        "        metrics=[\n",
        "            LLMContextRecall(),\n",
        "            Faithfulness(),\n",
        "            FactualCorrectness(),\n",
        "            ResponseRelevancy(),\n",
        "            ContextEntityRecall(),\n",
        "            NoiseSensitivity()\n",
        "        ],\n",
        "        llm=evaluator_llm,\n",
        "        run_config=custom_run_config\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    retrieval_results[name] = result\n",
        "\n",
        "# Convert results into a dataframe\n",
        "df_results = pd.DataFrame(retrieval_results).T\n",
        "\n",
        "# Display results\n",
        "display(df_results)\n",
        "\n",
        "# Visualization (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_results.plot(kind=\"bar\", figsize=(12, 6), title=\"Retriever Performance Metrics\")\n",
        "plt.xlabel(\"Retrievers\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'BM25': {'context_recall': 0.4667, 'faithfulness': 0.4883, 'factual_correctness': 0.3400, 'answer_relevancy': 0.9471, 'context_entity_recall': 0.3533, 'noise_sensitivity_relevant': 0.2024},\n",
              " 'Naive': {'context_recall': 0.7667, 'faithfulness': 0.7566, 'factual_correctness': 0.4140, 'answer_relevancy': 0.9467, 'context_entity_recall': 0.5367, 'noise_sensitivity_relevant': 0.5144},\n",
              " 'Multi-Query': {'context_recall': 0.7667, 'faithfulness': 0.9357, 'factual_correctness': 0.3790, 'answer_relevancy': 0.8474, 'context_entity_recall': 0.4533, 'noise_sensitivity_relevant': 0.4333},\n",
              " 'Parent-Document': {'context_recall': 0.4250, 'faithfulness': 0.6833, 'factual_correctness': 0.2660, 'answer_relevancy': 0.9512, 'context_entity_recall': 0.4333, 'noise_sensitivity_relevant': 0.3317},\n",
              " 'Contextual Compression': {'context_recall': 0.5167, 'faithfulness': 0.7223, 'factual_correctness': 0.3200, 'answer_relevancy': 0.8432, 'context_entity_recall': 0.4333, 'noise_sensitivity_relevant': 0.3442},\n",
              " 'Ensemble': {'context_recall': 0.8000, 'faithfulness': 0.8375, 'factual_correctness': 0.3560, 'answer_relevancy': 0.9412, 'context_entity_recall': 0.5000, 'noise_sensitivity_relevant': 0.7917},\n",
              " 'Semantic': {'context_recall': 0.8167, 'faithfulness': 0.8062, 'factual_correctness': 0.3575, 'answer_relevancy': 0.7641, 'context_entity_recall': 0.5433, 'noise_sensitivity_relevant': 0.6127}}"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_results\n",
        "\n"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How does John Wick compare to Liam Neeson's role in Taken?\n",
            "Response: content=\"John Wick, played by Keanu Reeves, is compared to Liam Neeson's role in Taken in terms of the premise of seeking revenge for a loved one taken from them. In Taken, Liam Neeson's character seeks to rescue his daughter, while in John Wick, Keanu Reeves seeks revenge for his dog. Both are action movies with a simple premise revolving around a relatable hero.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 522, 'total_tokens': 603, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-ba69b44e-d2ea-458c-997e-58d49339bb4f-0' usage_metadata={'input_tokens': 522, 'output_tokens': 81, 'total_tokens': 603, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: Whos Jon Wick?\n",
            "Response: content=\"John Wick is a character played by Keanu Reeves in the John Wick film series. He is initially introduced as a man who has just lost his wife and is trying to rebuild his life. Wick's life takes a turn when he is attacked by a young punk, and it is revealed that Wick is a super-assassin. In the following films, despite trying to retire, he is continuously pulled back into the criminal underworld due to his obligations and the actions of other criminals. Wick is known for his ability to evade death, his stealth, and his quick reflexes, leading some to refer to him as a supernatural being.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 127, 'prompt_tokens': 548, 'total_tokens': 675, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-84776aaf-a3ab-45d4-93cb-c359581b53df-0' usage_metadata={'input_tokens': 548, 'output_tokens': 127, 'total_tokens': 675, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: Why Keanu so good in John Wick?\n",
            "Response: content=\"Keanu Reeves excels in the John Wick series due to his slick performance as the titular character. His portrayal of John Wick is so convincing that audiences don't doubt his character even in implausible situations. His acting performance is confident and cool, emulating the swagger of action stars from the 70s. Moreover, the action sequences, including the gun shooting scenes, are meticulously choreographed and brilliantly shot, and Reeves performs them with great proficiency. These factors contribute to making Keanu Reeves' performance in John Wick outstanding.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 855, 'total_tokens': 963, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-ef667d34-5c90-4f80-8a7b-2954bed8357b-0' usage_metadata={'input_tokens': 855, 'output_tokens': 108, 'total_tokens': 963, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: What role do Russian mobsters play in the movie John Wick?\n",
            "Response: content=\"In the first John Wick movie, a young Russian-American punk, who is the son of a big-time Russian mobster, notices Wick's classic car and tries to buy it. When Wick refuses, the punk and his goons attack Wick at his home, beat him up, destroy his stuff, kill his dog, and steal his car. This triggers Wick, who is a super-assassin, to seek revenge. The Russian mobster and his gang then become Wick's opponents.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 556, 'total_tokens': 654, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-c0e1b721-e7ac-491d-a7ae-f04edae59e9c-0' usage_metadata={'input_tokens': 556, 'output_tokens': 98, 'total_tokens': 654, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: Whoo is Jon Wick?\n",
            "Response: content='John Wick is a character played by Keanu Reeves in a series of action films. The character is portrayed as a super-assassin who is known for his exceptional skills and ability to survive against all odds. He initially retires from his violent career after the death of his wife but is compelled to return to it following a series of events. Despite his age, he is depicted as having lightning-fast reflexes, an uncanny ability to evade death, and the skill to appear and disappear like a ninja.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 549, 'total_tokens': 652, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-86becd47-41d7-4a56-9787-55a754762587-0' usage_metadata={'input_tokens': 549, 'output_tokens': 103, 'total_tokens': 652, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: What makes the action sequences in John Wick stand out, and how does Keanu Reeves' portrayal contribute to the film's emotional depth and noir-inspired world?\n",
            "Response: content=\"The action sequences in John Wick stand out due to their sheer brilliance and meticulous choreography. They are described as being briskly paced and brilliantly shot, contributing to the overall excitement and appeal of the film. The sequences are also noted for their intensity, especially in scenes like the showdown between thugs and Wick in a nightclub. Keanu Reeves' portrayal of John Wick adds to the film's emotional depth and noir-inspired world by embodying the character with a cool confidence, even in implausible situations. His performance is slick and he portrays the character in such a way that audiences don't doubt his actions, even when he is violently brutal. Furthermore, his character is not a traditional hero but is more ruthless than the other characters, creating a unique dynamic that pushes the boundaries of traditional morality in film.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 832, 'total_tokens': 993, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-0832830f-3d7a-4c59-83bf-71eef27070c7-0' usage_metadata={'input_tokens': 832, 'output_tokens': 161, 'total_tokens': 993, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: How does Ian McShane's character influence John Wick's actions in the sequel, and what are the consequences of these actions?\n",
            "Response: content=\"In the sequel, Ian McShane's character calls on John Wick to repay an old debt. This debt requires Wick to help McShane take over the Assassin's Guild. This takes Wick on a journey to Italy, Canada, and Manhattan, where he has to kill a large number of assassins. The consequence of these actions is a lot of carnage and further entanglement in the world of assassins.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 587, 'total_tokens': 673, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4e24131a-b981-4886-abbb-d5649ca0aaa3-0' usage_metadata={'input_tokens': 587, 'output_tokens': 86, 'total_tokens': 673, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: What elements did John Wick 3 incorporate to create something special and unique, despite its troubled release history?\n",
            "Response: content='John Wick 3 incorporated several unique elements to stand out. The film continued its emphasis on high-quality, virtuoso action sequences, avoiding common cinematic techniques like quick-cuts and shaky cameras thus allowing viewers to fully experience the action. The franchise also further pushed the boundaries of action movies, with the third installment feeling more intense than the previous ones, yet still not feeling too long despite its near 3-hour duration. The set pieces were especially noteworthy, with scenes like the Tokyo sequence with illuminated cherry blossoms adding a beautiful and artistic touch to the action. Despite some illogical moments, the film managed to keep the spirit of the franchise alive and meet the high expectations set by its predecessors.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 673, 'total_tokens': 813, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-728b734f-2e61-496e-9c40-b1d30408178a-0' usage_metadata={'input_tokens': 673, 'output_tokens': 140, 'total_tokens': 813, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: How does the action and style in 'John Wick: Chapter 3 - Parabellum' compare to the reception and perceived quality of 'John Wick: Chapter 4'?\n",
            "Response: content='Both \\'John Wick: Chapter 3 - Parabellum\\' and \\'John Wick: Chapter 4\\' are highly praised for their action sequences and style. \\'Parabellum\\' is described as a \"visually gorgeous\", \"entertaining\", and \"simplistic thriller\" with \"electrifying action\", \"beautiful cinematography\", and a \"pulsating score\". It is also noted for its sense of humor and overall entertainment value. \\n\\n\\'Chapter 4\\', on the other hand, is lauded for continuing the tradition of non-stop action from start to finish. It is recognized as an improvement on its predecessor and solidifies Keanu Reeves\\' status as a leading martial arts action star, as well as his pairing with Director Chad Stahelski as one of the greatest martial arts action duos of modern times. Thus, both films are highly regarded, though \\'Chapter 4\\' seems to have surpassed \\'Parabellum\\' in terms of its action and the performances of its lead star and director.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 213, 'prompt_tokens': 304, 'total_tokens': 517, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-cdb13365-6805-4831-a279-f98335c9dc42-0' usage_metadata={'input_tokens': 304, 'output_tokens': 213, 'total_tokens': 517, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "Question: Wut makes Keanu's action in John Wick so amazin?\n",
            "Response: content=\"Keanu Reeves' performance as John Wick is highly praised for several reasons. He delivers a slick performance with confidence and coolness, handling even ridiculously intense action sequences with believability. His knowledge of the technical aspects of shooting action scenes contributes greatly to the expertly choreographed and filmed sequences. The action scenes, particularly gun shooting scenes, are described as incredibly entertaining and cool. Additionally, his character's ruthlessness and intensity add to the overall appeal. His performance elevates the films and has set a standard for action in Hollywood.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 1034, 'total_tokens': 1143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-0266bbd6-b2da-4263-8385-376d7e2ab711-0' usage_metadata={'input_tokens': 1034, 'output_tokens': 109, 'total_tokens': 1143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "----------------------------------------\n",
            "\n",
            "Generated RAGAS Dataset:\n",
            "EvaluationDataset(features=['eval_sample', 'synthesizer_name'], len=10)\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4\")\n",
        "\n",
        "# Query Generation Chain (Updated)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"original_query\"],\n",
        "    template=\"Generate 3 different ways to ask the following question:\\n{original_query}\",\n",
        ")\n",
        "query_generation_chain = prompt | llm  # NEW method replacing LLMChain\n",
        "\n",
        "# RAG-Fusion Function\n",
        "def rag_fusion(original_query, naive_retriever, llm):\n",
        "    \"\"\" Performs RAG Fusion using reciprocal rank fusion (RRF) on retrieved documents. \"\"\"\n",
        "    try:\n",
        "        # Generate alternative queries using the new method\n",
        "        generated_queries = query_generation_chain.invoke({\"original_query\": original_query})\n",
        "        generated_queries_list = generated_queries.content.strip().split(\"\\n\")\n",
        "        generated_queries_list = [q.lstrip(\"123. \") for q in generated_queries_list if q.strip()]\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating queries: {e}\")\n",
        "        return \"Error in query generation\"\n",
        "\n",
        "    # Retrieve documents using the new method\n",
        "    retrieved_docs_per_query = []\n",
        "    for query in generated_queries_list:\n",
        "        docs = naive_retriever.invoke(query) if naive_retriever else []\n",
        "        if docs:\n",
        "            retrieved_docs_per_query.append(docs)\n",
        "\n",
        "    if not retrieved_docs_per_query:\n",
        "        return \"No relevant documents found.\"\n",
        "\n",
        "    # ✅ Fixed: Reciprocal Rank Fusion (RRF)\n",
        "    def reciprocal_rank_fusion(retrieved_docs_per_query, k=60):\n",
        "        \"\"\" Combines documents using RRF to improve retrieval diversity. \"\"\"\n",
        "        ranked_results = {}\n",
        "\n",
        "        for docs in retrieved_docs_per_query:\n",
        "            for rank, doc in enumerate(docs):\n",
        "                # ✅ Use a hashable unique identifier (falling back to content preview if no metadata)\n",
        "                doc_id = doc.metadata.get(\"source\", doc.page_content[:50])  # Unique ID for document\n",
        "                \n",
        "                if doc_id not in ranked_results:\n",
        "                    ranked_results[doc_id] = {\"score\": 0, \"document\": doc}  # Store document reference\n",
        "                \n",
        "                ranked_results[doc_id][\"score\"] += 1 / (rank + k)\n",
        "\n",
        "        # ✅ Sort based on score\n",
        "        fused_results = sorted(ranked_results.values(), key=lambda x: x[\"score\"], reverse=True)\n",
        "        \n",
        "        # ✅ Return only documents (not just identifiers)\n",
        "        return [entry[\"document\"] for entry in fused_results]\n",
        "\n",
        "    fused_docs = reciprocal_rank_fusion(retrieved_docs_per_query)\n",
        "\n",
        "    # ✅ Construct context from top-ranked documents\n",
        "    context = \"\\n\".join([doc.page_content for doc in fused_docs[:5]])  # Top 5 docs\n",
        "\n",
        "    # ✅ Structured prompt for LLM\n",
        "    prompt_text = f\"\"\"\n",
        "    You are an expert AI assistant. Use the following retrieved context to answer the user's question.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question: {original_query}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        answer = llm.invoke(prompt_text)  # ✅ Use .invoke() instead of direct call\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return \"Error in LLM response\"\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Sample dataset iteration\n",
        "if \"dataset\" not in locals():\n",
        "    dataset = []  # Placeholder dataset\n",
        "\n",
        "for test_row in dataset:\n",
        "    user_question = test_row.eval_sample.user_input\n",
        "    response = rag_fusion(user_question, naive_retriever, llm)\n",
        "    print(f\"Question: {user_question}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print(\"-\" * 40)  # Separator for readability\n",
        "\n",
        "# Display the generated RAGAS dataset\n",
        "print(\"\\nGenerated RAGAS Dataset:\")\n",
        "print(dataset)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
